<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kyle M. Douglass</title><link>https://kylemdouglass.com/</link><description>Optics, programming, and biophysics</description><atom:link href="https://kylemdouglass.com/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2024 &lt;a href="mailto:kyle.m.douglass@gmail.com"&gt;Kyle M. Douglass&lt;/a&gt; 
&lt;a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Tue, 21 May 2024 10:47:25 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Automated Testing of Simulation Code via Hypothesis Testing</title><link>https://kylemdouglass.com/posts/testing-simulation-code/</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;h2&gt;Missing a Theory of Testing for Scientific Code&lt;/h2&gt;
&lt;p&gt;If you search the Internet for resources on the theory of testing code, you will find information about the different types of tests and how to write them. You will also find that it is generally accepted among programmers that good code is tested and bad code is not. The problem for scientists and engineers, however, is that the theory concerning the testing of computer code was developed primarily by programmers that work on systems that model business processes. There is little theory on how, for example, to test the outcome of physics simulations. To further exacerbate the problem, scientific programmers feel obliged to write tests without the guidance of such a theory because of the imperative to test their code. This leads to convoluted tests that are difficult to understand and maintain.&lt;/p&gt;
&lt;h3&gt;Scientific Code is Different&lt;/h3&gt;
&lt;p&gt;Code that models business processes is based on explicit rules that are developed from a set of requirements. An example of a rule that a business system might follow is "If a customer has ordered an item and has not paid, then send her an invoice."&lt;/p&gt;
&lt;p&gt;To test the above rule, we write out all the possible cases and write a test for each one. For example:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A customer orders an item without paying. Expected result: an invoice is sent.&lt;/li&gt;
&lt;li&gt;A customer orders an item and pays at the time of checkout: Expected result: no invoice is sent.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I have found that a good way to identify test cases in business logic is to look for if/else statements in a rule. Each branch of the statement should be a different test.&lt;/p&gt;
&lt;p&gt;Now let's consider a physics simulation. I am an optical engineer, so I will use an example from optics. One thing I have often done in my work is to simulate the image formation process of a lens system, including the noise imparted by the camera. A simple model of a CMOS camera pixel is one that takes an input signal in photons, adds shot noise, converts it to photoelectrons, adds dark noise, and then converts the electron signal into analog-to-digital units. Schematically:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;photons&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;--&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;electrons&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;--&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ADUs&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A simplified Python code snippet that models this process, including noise, is below. An instance of the camera class has a method called &lt;code&gt;snap&lt;/code&gt; that takes input array of photons and converts it to ADUs.&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dataclasses&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;dataclass&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;


&lt;span class="nd"&gt;@dataclass&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Camera&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;baseline&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;  &lt;span class="c1"&gt;# ADU&lt;/span&gt;
    &lt;span class="n"&gt;bit_depth&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;
    &lt;span class="n"&gt;dark_noise&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;6.83&lt;/span&gt;  &lt;span class="c1"&gt;# e-&lt;/span&gt;
    &lt;span class="n"&gt;gain&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.12&lt;/span&gt;  &lt;span class="c1"&gt;# ADU / e-&lt;/span&gt;
    &lt;span class="n"&gt;quantum_efficiency&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.76&lt;/span&gt;
    &lt;span class="n"&gt;well_capacity&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;32406&lt;/span&gt;  &lt;span class="c1"&gt;# e-&lt;/span&gt;
    &lt;span class="n"&gt;rng&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Generator&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;default_rng&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;snap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;signal&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# Simulate shot noise and convert to electrons&lt;/span&gt;
        &lt;span class="n"&gt;photoelectrons&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rng&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;poisson&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;quantum_efficiency&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;signal&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;signal&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# Add dark noise&lt;/span&gt;
        &lt;span class="n"&gt;electrons&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rng&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dark_noise&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;photoelectrons&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;photoelectrons&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# Clip to the well capacity to model electron saturation&lt;/span&gt;
        &lt;span class="n"&gt;electrons&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;electrons&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;well_capacity&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# Convert to ADU&lt;/span&gt;
        &lt;span class="n"&gt;adu&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;electrons&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gain&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;baseline&lt;/span&gt;

        &lt;span class="c1"&gt;# Clip to the bit depth to model ADU saturation&lt;/span&gt;
        &lt;span class="n"&gt;adu&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;adu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bit_depth&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;adu&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint16&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;How can we test this code? In this case, there are no if/else statements to help us identify test cases. Some possible solutions are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;An expert can review it. But what if we don't have an expert? Or, if you are an expert, how do we know that we haven't made a mistake? I have worked professionally as both an optical and a software engineer and I can tell you that I make coding mistakes many times a day. And what if the simulation is thousands of lines of code? This solution, though useful, cannot be sufficient for testing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute what the results ought to be for a given set of inputs. Rules like "If the baseline is 100, and the bit depth is 12, etc., then the output is 542 ADU" are not that useful here because the output is random.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Evaluate the code and manually check that it produces the desired results. This is similar to expert review. The problem with this approach is that you would need to recheck the code every time a change is made. One of the advantages of testing business logic is that the tests can be automated. It would be advantageous to preserve automation in testing scientific code.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We could always fix the value of the seed for the random number generator to at least make the test deterministic, but then we would not know whether the variation in the simulation output is what we would expect from run-to-run. I'm also unsure whether the same seed produces the same results across different hardware architectures. Since the simulation is non-deterministic at its core, it would be nice to include this attribute within the test case.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Automated Testing of Simulation Results via Hypothesis Testing&lt;/h2&gt;
&lt;p&gt;The solution that I have found to the above-listed problems is derived from ideas that I learned in a class on quality control that I took in college. In short, we run the simulation a number of times and compute one or more statistics from the results. The statistics are compared to their theoretical values in a hypothesis test, and, if the result is outside of a given tolerance, the test fails. If the probability of failure is made small enough, then a failure of the test &lt;strong&gt;practically&lt;/strong&gt; indicates an error in the simulation code rather than a random failure due to the stochastic output.&lt;/p&gt;
&lt;h3&gt;Theoretical Values for Test Statistics&lt;/h3&gt;
&lt;p&gt;In the example of a CMOS camera, both the theoretical mean and the variance of a pixel are known. The &lt;a href="https://www.emva.org/standards-technology/emva-1288/"&gt;EMVA 1288 Linear Model&lt;/a&gt; states that&lt;/p&gt;
&lt;p&gt;$$ \mu_y = K \left( \eta \mu_p + \mu_d \right) + B $$&lt;/p&gt;
&lt;p&gt;where \( \mu_y \) is the mean ADU count, \( K \) is the gain, \( \eta \) is the quantum efficiency, \( \mu_p \) is the mean photon count, \( \mu_d \) is the mean dark noise, and \( B \) is the baseline value, i.e. the average ADU count under no illumination. Likewise, the variance of the pixel describes the noise:&lt;/p&gt;
&lt;p&gt;$$ \sigma_y = \sqrt{K^2 \sigma_d^2 + \sigma_q^2 + K \left( \mu_y - B \right)} $$&lt;/p&gt;
&lt;p&gt;where \( \sigma_y \) is the standard deviation of the ADU counts, \( \sigma_d^2 \) is the dark noise variance, and \( \sigma_q^2 = 1 / 12 \, \text{ADU} \) is the quantization noise, i.e. the noise from converting an analog voltage into discrete ADU values.&lt;/p&gt;
&lt;h3&gt;Hypothesis Testing&lt;/h3&gt;
&lt;p&gt;We can formulate a hypothesis test for each test statistic. The test for each is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Null hypothesis :&lt;/strong&gt; the simulation statistics and the theoretical values are the same&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alternative hypothesis :&lt;/strong&gt; the simulation statistics and the theoretical values are different&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let's first focus on the mean pixel values. To perform this hypothesis test, I ran the simulation code a number of times. For convenience, I chose an input signal of 1000 photons. Here's the resulting histogram:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://kylemdouglass.com/images/camera-mean-adus.png"&gt;&lt;/p&gt;
&lt;p&gt;The mean of this distribution is 190.721 ADU and the standard deviation is 3.437 ADU. The theoretical values are 191.2 ADU and 3.420 ADU, respectively. Importantly, if I re-run the simulation, then I get a different histogram because the simulation's output is random.&lt;/p&gt;
&lt;p&gt;The above histogram is called the &lt;strong&gt;sampling distribution of the mean&lt;/strong&gt;, and its width is proportional to the &lt;strong&gt;standard error of the mean&lt;/strong&gt;.&lt;/p&gt;
&lt;h4&gt;Hypothesis Testing of the Mean Pixel Value&lt;/h4&gt;
&lt;p&gt;To perform the hypthosesis test on the mean, I build a confidence interval around the simulated value using the following formula:&lt;/p&gt;
&lt;p&gt;$$ \mu_y \pm X \frac{s}{\sqrt{N}} $$&lt;/p&gt;
&lt;p&gt;Here \( s \) is my estimated standard deviation (3.437 ADU in the example above), and \( N = 10,000 \) is the number of simulated values. Their ratio \( \frac{s}{\sqrt{N}} \) is an estimate of the &lt;strong&gt;standard error of the mean&lt;/strong&gt;. \( X \) is a proportionality factor that is essentially a tolerance on how close the simulated value must be to the theoretical one to be considered "equal". A larger tolerance means that it is less likely that the hypothesis test will fail, but I am less certain that the value of the simulation is exactly equal to the theoretical value.&lt;/p&gt;
&lt;p&gt;If this looks familiar, it should. In introductory statistics classes, this approach is called &lt;a href="https://en.wikipedia.org/wiki/Student%27s_t-test"&gt;Student's one sample t-test&lt;/a&gt;. In the t-test, the value for \( X \) is denoted as \( t \) and depends on the desired confidence level and on the number of data points in the sample. (Strictly speaking, it's the number of data points minus 1.)&lt;/p&gt;
&lt;p&gt;As far as I can tell there's no rule for selecting a value of \( X \); rather, it's a free parameter. I often choose 3. Why? Well, if the sampling distribution is approximately normally distributed, and the number of sample points is large, then the theoretical mean should lie within 3 standard errors of the simulated one approximately 99.7% of the time &lt;strong&gt;if the algorithm is correct.&lt;/strong&gt; Alternatively, this means that a correct simulation will produce a result that is more than three standard errors from the theoretical mean about every 1 out of 370 test runs.&lt;/p&gt;
&lt;h4&gt;Hypothesis Testing of the Noise&lt;/h4&gt;
&lt;p&gt;Recall that standard deviation of pixel values is a measure of the noise. The approach to testing it remains the same as before. We write the confidence interval as&lt;/p&gt;
&lt;p&gt;$$ \sigma_y \pm X \left( s.e. \right) $$&lt;/p&gt;
&lt;p&gt;where we have \( s.e. \) as the standard error of the standard deviation. If the simulated standard deviation is outside this interval, then we reject the null hypothesis and fail the test.&lt;/p&gt;
&lt;p&gt;Now, how do we calculate the standard error of the standard deviation? Unlike with the mean value, we have only one value for the standard deviation of the pixel values. Furthermore, there doesn't seem to be a simple formula for the standard error of the variance or standard error of the standard deviation. (I looked around the Math and Statistics Stack Exchanges, but what I did find produced standard errors that were way too large.)&lt;/p&gt;
&lt;p&gt;Faced with this problem, I have two options:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;run the simulation a number of times to get a distribution of standard deviations&lt;/li&gt;
&lt;li&gt;draw pixel values from the existing simulation data &lt;strong&gt;with replacement&lt;/strong&gt; to estimate the sampling distribution. This approach is known as &lt;a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)"&gt;bootstrapping&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this situation, both are valid approaches because the simulation runs quite quickly. However, if the simulation is slow, bootstrapping might be desirable because resampling the simulated data is relatively fast.&lt;/p&gt;
&lt;p&gt;I provide below a function that makes a bootstrap estimate of the standard error of pixel values to give you an idea of how this works. It draws &lt;code&gt;n&lt;/code&gt; samples from the simulated pixel values with replacement and places the results in the rows of an array. Then, the standard devation of each row is computed. Finally, since the standard error is the standard deviation of the sampling distribution, the standard deviation of resampled standard deviations is computed and returned.&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;se_std&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;std_sampling_distribution&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std_sampling_distribution&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Of course, the value of &lt;code&gt;n&lt;/code&gt; in the function above is arbitrary. From what I can tell, setting &lt;code&gt;n&lt;/code&gt; to be the size of the data is somewhat standard practice.&lt;/p&gt;
&lt;h4&gt;Automated Hypothesis Testing&lt;/h4&gt;
&lt;p&gt;At this point, we can calculate the probability that the mean and standard deviation of the simulated pixel values will lie farther than some distance from their theoretical values. This means that we know roughly how often a test will fail due to pure luck.&lt;/p&gt;
&lt;p&gt;To put these into an automated test function, we need only translate the two hypotheses into an assertion. The null hypothesis should correspond to the argument of the assertion being true; the alternative hypothesis corresponds to a false argument.&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;TOL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;test_cmos_camera&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;camera&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;num_pixels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;
    &lt;span class="n"&gt;mean_photons&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
    &lt;span class="n"&gt;photons&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean_photons&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_pixels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;expected_mean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;191.2&lt;/span&gt;
    &lt;span class="n"&gt;expected_std&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;3.42&lt;/span&gt;

    &lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;camera&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;snap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;photons&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;tol_mean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TOL&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_pixels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num_pixels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;tol_std&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TOL&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;se_std&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isclose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;expected_mean&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;atol&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tol_mean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isclose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;expected_std&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;atol&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tol_std&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;With a &lt;code&gt;TOL&lt;/code&gt; value of 3 and with the sampling distributions being more-or-less normally distributed, each assertion should fail about 1 / 370 times because the area in the tails of the distribution beyond three standard errors is 1 / 370. We can put this test into our test suite and continuous integration (CI) system and run it automatically using whatever tools we wish, e.g. GitHub Actions and pytest.&lt;/p&gt;
&lt;h2&gt;Discussion&lt;/h2&gt;
&lt;h3&gt;Non-deterministic Tests&lt;/h3&gt;
&lt;p&gt;It is an often-stated rule of thumb that automated tests should never fail randomly because it makes failures difficult to diagnose and makes you likely to ignore the tests. Here however it is in the very nature of this test that it will fail randomly from time to time. What are we to do?&lt;/p&gt;
&lt;p&gt;An easy solution would be to isolate these sorts of tests and run them separately from the deterministic ones so that we know exactly where the error occurred. Then, if there is a failure of the non-deterministic tests, the CI could just run them again. If &lt;code&gt;TOL&lt;/code&gt; is set so that a test failure is very rare, then any failure of these tests twice would practically indicate a failure of the algorithm to produce the theoretical results.&lt;/p&gt;
&lt;h3&gt;Testing Absolute Tolerances&lt;/h3&gt;
&lt;p&gt;It could be argued that what I presented here is a lot of work just to make an assertion that a simulation result is close to a known value. In other words, it's just a fancy way to test for absolute tolerances, and possibly is more complex than it needs to be. I can't say that I entirely disagree with this.&lt;/p&gt;
&lt;p&gt;As an alternative, consider the following: if we run the simulation a few times we can get a sense of the variation in its output, and we can use these values to roughly set a tolerance that states by how much the simulated and theoretical results should differ. This is arguably faster than constructing the confidence intervals like we did above.&lt;/p&gt;
&lt;p&gt;The value in the hypothesis testing approach is that you can know the probability of failure to a high degree of accuracy. Whether or not this is important probably depends on what you want to do, but it does provide you with a deeper understanding of the behavior of the simulation that might help debug difficult problems.&lt;/p&gt;
&lt;h3&gt;Testing for Other Types of Errors&lt;/h3&gt;
&lt;p&gt;There are certainly other problems in testing simulation code that are not covered here. The above approach won't tell you directly if you have entered an equation incorrectly. It also requires theoretical values for the summary statistics of the simulation's output. If you have a theory for these already, you might argue that a simulation would be superfluous.&lt;/p&gt;
&lt;p&gt;If it's easy to implement automated tests for your simulation that are based on hypothesis testing, and if you expect the code to change often, then having a few of these sorts of tests will at least provide you a degree of confidence that everything is working as you expect as you make changes. And that is one of the goals of having automated tests: fearless refactoring.&lt;/p&gt;
&lt;h3&gt;Testing the Frequency of Failures&lt;/h3&gt;
&lt;p&gt;I stated often that with hypothesis testing we know how often the code should fail, but we never actually tested that. We could have run the simulation a large number of times and verified that the number of failures was approximately equal to the theoretical number of failures.&lt;/p&gt;
&lt;p&gt;To my mind, it seems that this is just the exact same problem that was addressed above, but instead of testing summary statistics on the output values we test the number of failures. And since the number of failures will vary randomly, we would need a sampling distribution for this. So really this approach requires more CPU clock cycles to do the same thing because we need to run the simulation a large number of times.&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Automated testing of simulation code is different than testing business logic due to its stochastic nature and inability to be reduced to "rules"&lt;/li&gt;
&lt;li&gt;We can formulate hypothesis tests to determine how often the simulation produces values that are farther than a given distance from what theory predicts&lt;/li&gt;
&lt;li&gt;The hypothesis tests can be translated into test cases: accepting the null hypothesis means the test passes, whereas rejecting the null hypothesis means the test fails&lt;/li&gt;
&lt;li&gt;Non-deterministic testing is useful when it is quick to implement and you expect to change the code often&lt;/li&gt;
&lt;/ul&gt;</description><category>cameras</category><category>simulation</category><category>statistics</category><guid>https://kylemdouglass.com/posts/testing-simulation-code/</guid><pubDate>Tue, 21 May 2024 07:54:40 GMT</pubDate></item><item><title>French Vocabulary for Machinists</title><link>https://kylemdouglass.com/posts/french-vocabulary-for-machinists/</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;p&gt;I work in a French-speaking country and frequently need to communicate with our machinists, many of whom do not speak English.&lt;/p&gt;
&lt;p&gt;Here is a list of English-French vocabulary words that I have found useful. I will update it as I learn more words.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Last update: 2024-04-18&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Materials and processing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;aluminum&lt;/strong&gt;, &lt;em&gt;n&lt;/em&gt; : aluminium (m)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;anodized&lt;/strong&gt;, &lt;em&gt;adj&lt;/em&gt; : anodisé&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;stainless steel&lt;/strong&gt;, &lt;em&gt;n&lt;/em&gt; : 1. acier inoxydable, 2. inox (the cool way to say it)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Measurements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;dimensions&lt;/strong&gt;, &lt;em&gt;npl&lt;/em&gt; : les dimensions (fpl) &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Screws, bolts, fasteners, etc.&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;latch&lt;/strong&gt;, &lt;em&gt;n&lt;/em&gt; : un loquet (possibly Swiss-French)&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;push latch&lt;/strong&gt;, &lt;em&gt;n&lt;/em&gt; : un loquet poussoir&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;screw&lt;/strong&gt;, &lt;em&gt;n&lt;/em&gt; : une vis&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;cap (or head) screw&lt;/strong&gt;, &lt;em&gt;n&lt;/em&gt; : une vis à tête&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;countersunk cap screw&lt;/strong&gt;, &lt;em&gt;n&lt;/em&gt; : vis à tête fraisée&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;spring&lt;/strong&gt;, &lt;em&gt;n&lt;/em&gt; : un ressort&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;threading&lt;/strong&gt;, &lt;em&gt;n&lt;/em&gt; : un filetage&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;exterior threads&lt;/strong&gt; : 1. filetage extérieur, 2. filetages mâles &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;interior threads&lt;/strong&gt; : 1. filetage intérieur, 2. filetages femelles  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Tools&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;die&lt;/strong&gt;, &lt;em&gt;n&lt;/em&gt; : une filière&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;lathe&lt;/strong&gt;, &lt;em&gt;n&lt;/em&gt; : un tour&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mill&lt;/strong&gt;, &lt;strong&gt;milling machine&lt;/strong&gt;, &lt;em&gt;n&lt;/em&gt; : une fraiseuse&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tap&lt;/strong&gt;, &lt;em&gt;n&lt;/em&gt; : un taraud&lt;/li&gt;
&lt;/ul&gt;</description><category>french</category><guid>https://kylemdouglass.com/posts/french-vocabulary-for-machinists/</guid><pubDate>Thu, 28 Mar 2024 08:35:27 GMT</pubDate></item><item><title>Engineering Fits</title><link>https://kylemdouglass.com/posts/engineering-fits/</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;p&gt;I have been working on some optomechanical parts that require a hole-and-shaft style mating. During their design, I realized I really didn't have any theoretical background on how big the holes and shafts should be so that they fit together. This lead me to do some basic research into &lt;strong&gt;engineering fits&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;Engineering Fits&lt;/h2&gt;
&lt;p&gt;According to &lt;cite&gt;Building Scientific Apparatus, 4th ed.&lt;a href="https://www.cambridge.org/core/books/building-scientific-apparatus/52BB9BC3EDF3A8F604EF95D83901AA00"&gt;1&lt;/a&gt;&lt;/cite&gt;, fit should be specified when the absolute size of two mating parts is not important, but the clearance between them is critical.&lt;/p&gt;
&lt;p&gt;To understand fits, it helps first to think in terms of active surfaces and tolerances.&lt;/p&gt;
&lt;p&gt;An &lt;strong&gt;active surface&lt;/strong&gt; is a region where two surfaces touch and either move against each other or have a static fit &lt;a href="https://formlabs.com/eu/blog/3D-printing-tolerances-for-engineering-fit/"&gt;2&lt;/a&gt;. (Interestingly, an active surface is really two physical surfaces by this definition.) The tolerances on the size of two mating parts determines the type of fit. An example of the tolerances on a hole-and-shaft assembly is shown below.&lt;/p&gt;
&lt;p&gt;&lt;svg width="150mm" height="100mm" viewbox="0 0 150 100" version="1.1" id="svg5" xmlns="http://www.w3.org/2000/svg" xmlns:svg="http://www.w3.org/2000/svg"&gt;
  &lt;defs id="defs2"&gt;&lt;/defs&gt;
  &lt;g id="layer1"&gt;
    &lt;g id="g17422" transform="translate(4.3342147,0.28437662)"&gt;
      &lt;g id="g18330" transform="translate(7.3550761,0.97463966)"&gt;
        &lt;rect style="fill:#a8a8a8;fill-opacity:1;stroke:none;stroke-width:0.0499999;stroke-linecap:square;stroke-dasharray:0.0999994, 0.199999;stroke-dashoffset:0;stroke-opacity:1" id="rect8681" width="61.416935" height="6.1849809" x="-1.2360383" y="24.001053" ry="2.3741585e-07"&gt;&lt;/rect&gt;
        &lt;rect style="fill:#a8a8a8;fill-opacity:1;stroke:none;stroke-width:0.0499999;stroke-linecap:square;stroke-dasharray:0.0999994, 0.199999;stroke-dashoffset:0;stroke-opacity:1" id="rect8943" width="61.416935" height="6.1849809" x="-1.2359573" y="67.295868" ry="2.3741585e-07"&gt;&lt;/rect&gt;
        &lt;rect style="fill:none;fill-opacity:1;stroke:#000000;stroke-width:0.199999;stroke-linecap:square;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1" id="rect8621" width="61.416935" height="92.190269" x="-1.2359573" y="2.645849" ry="1.7694015e-07"&gt;&lt;/rect&gt;
        &lt;path style="fill:none;fill-opacity:1;stroke:#000000;stroke-width:0.199999;stroke-linecap:square;stroke-dasharray:0.399999, 0.799999;stroke-dashoffset:0;stroke-opacity:1" d="M 60.180883,27.093527 H -1.2360264" id="path8677"&gt;&lt;/path&gt;
        &lt;path style="fill:none;fill-opacity:1;stroke:#000000;stroke-width:0.199999;stroke-linecap:square;stroke-dasharray:0.399999, 0.799999;stroke-dashoffset:0;stroke-opacity:1" d="M 60.18099,70.388445 H -1.2360264" id="path8679"&gt;&lt;/path&gt;
        &lt;rect style="fill:#a8a8a8;fill-opacity:1;stroke:none;stroke-width:0.199999;stroke-linecap:square;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1" id="rect9673" width="61.708443" height="6.1849813" x="66.149086" y="62.016087" ry="2.3741585e-07"&gt;&lt;/rect&gt;
        &lt;rect style="fill:#a8a8a8;fill-opacity:1;stroke:none;stroke-width:0.199999;stroke-linecap:square;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1" id="rect9677" width="61.708443" height="6.1849813" x="66.149086" y="31.09115" ry="2.3741585e-07"&gt;&lt;/rect&gt;
        &lt;rect style="fill:none;fill-opacity:1;stroke:#000000;stroke-width:0.199999;stroke-linecap:square;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1" id="rect9671" width="61.708359" height="30.924906" x="66.149086" y="34.183422" ry="2.3741585e-07"&gt;&lt;/rect&gt;
        &lt;g id="g18315" transform="translate(-24.896546)"&gt;
          &lt;rect style="fill:#a8a8a8;fill-opacity:1;stroke:none;stroke-width:0.2;stroke-linecap:square;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1" id="rect16362" width="9.260376" height="3.6321862" x="90.945633" y="88.398582" ry="1.394246e-07"&gt;&lt;/rect&gt;
          &lt;text xml:space="preserve" style="font-size:4.23333px;font-family:Arial;-inkscape-font-specification:'Arial, Normal';text-align:center;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.0499999;stroke-linecap:square;stroke-linejoin:bevel;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1" x="118.46138" y="91.428886" id="text12648"&gt;&lt;tspan id="tspan12646" style="font-size:4.23333px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.05" x="118.46138" y="91.428886"&gt;Tolerance Ranges&lt;/tspan&gt;&lt;/text&gt;
        &lt;/g&gt;
        &lt;path style="fill:#000000;fill-opacity:1;stroke:#000000;stroke-width:0.199999;stroke-linecap:butt;stroke-linejoin:round;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1" d="M 66.149086,49.64587 H 52.638712 l 0.728979,-0.628177 v 1.351618 L 52.638712,49.64587" id="path16428"&gt;&lt;/path&gt;
      &lt;/g&gt;
    &lt;/g&gt;
  &lt;/g&gt;
&lt;/svg&gt;&lt;/p&gt;
&lt;h3&gt;Fit definitions&lt;/h3&gt;
&lt;p&gt;In this context, we can define three types of fits:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Clearance fits&lt;/em&gt; : Tolerance zones do not overlap&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Transition fits&lt;/em&gt; : Tolerance zones partially overlap&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Interference fits&lt;/em&gt; : Tolerance zones fully overlap&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These fits exist on a continuum and are not neatly distinguished in practice. The continuum can be seen by plotting the force required for mating vs. the allowance. The allowance in this context can be defined as follows&lt;a href="https://waykenrm.com/blogs/difference-between-tolerance-and-allowance/"&gt;3&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;\[ \text{allowance} = \text{smallest hole} - \text{largest shaft} \]&lt;/p&gt;
&lt;h4&gt;Clearance fits&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Sliding fit&lt;/em&gt; : Some lateral play&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Running fit&lt;/em&gt; : More fricition, but more accurate motion&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Transition fits&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Keyring fit&lt;/em&gt; : Slight force required for mating and easy to remove&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Push fit&lt;/em&gt; : More force required; possible to remove by hand&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Interference fits&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Force fit&lt;/em&gt; : Hand tools likely required for mating&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Press fit&lt;/em&gt; : Requires more force, likely using a press&lt;/li&gt;
&lt;/ol&gt;</description><category>3d printing</category><category>fits</category><guid>https://kylemdouglass.com/posts/engineering-fits/</guid><pubDate>Tue, 26 Mar 2024 10:48:49 GMT</pubDate></item><item><title>A Simple Object-Space Telecentric System</title><link>https://kylemdouglass.com/posts/a-simple-object-space-telecentric-system/</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;h2&gt;Object-space telecentricity&lt;/h2&gt;
&lt;p&gt;I have been working on a software package recently for optical systems design. The process of building the package has proceeded like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Think of a particular case that I want to model; for example an infinite conjugate afocal system&lt;/li&gt;
&lt;li&gt;Implement it in the code&lt;/li&gt;
&lt;li&gt;Discover that the code doesn't work&lt;/li&gt;
&lt;li&gt;Create a test case that helps debug the code&lt;/li&gt;
&lt;li&gt;Repeat&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I am modeling a telecentric lens in the current iteration of this loop. To keep things simple, I am limiting myself to an &lt;a href="https://en.wikipedia.org/wiki/Telecentric_lens#Object-space_telecentric_lenses"&gt;object-space telecentric system&lt;/a&gt;. This was more challenging than I expected. In part, the reason is that I was trying to infer whether a system was or was not telecentric from the lens prescription data and a ray trace, which has two problems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I need to do a floating point comparison between two numbers to say whether a system is telecentric. Either the chief ray angle in object-space has to be zero or the entrance pupil must be located at infinity. Floating point comparisons are notoriously difficult to get right, and if you're doing them then you might want to rethink what you're trying to model.&lt;/li&gt;
&lt;li&gt;Numerous checks are needed before we can even trace any rays. For example, I should check first whether the user placed the object at infinity. This would form the image in the same plane as the aperture stop, which does not really make sense.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I find it interesting that &lt;a href="https://support.zemax.com/hc/en-us/articles/1500005488201-Modeling-a-lens-that-is-telecentric-in-image-space"&gt;Zemax addresses these problems&lt;/a&gt; by introducing object-space telecentricity as an extra boolean flag that forces the chief ray angle to be zero in the object-space. In other words, the user needs to know what they're doing and to specify that they want telecentricity from the beginning.&lt;/p&gt;
&lt;h2&gt;An object-space telecentric example&lt;/h2&gt;
&lt;p&gt;I adapted the following example from lens data presented in this video: &lt;a href="https://www.youtube.com/watch?v=JfstTsuNAz0"&gt;https://www.youtube.com/watch?v=JfstTsuNAz0&lt;/a&gt;. Notably, the object distance was increased by nearly a factor of two from what was given in the video so that the image plane was at a finite distance from the lens. Paraxial ray trace results were computed by hand.&lt;/p&gt;
&lt;table border="1"&gt;
    &lt;caption&gt;
        A simple object-space telecentric system comprising a planoconvex lens and a stop.
    &lt;/caption&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th scope="row"&gt;Surface&lt;/th&gt;
            &lt;th&gt;0&lt;/th&gt;
            &lt;th&gt;1&lt;/th&gt;
            &lt;th&gt;2&lt;/th&gt;
            &lt;th&gt;3&lt;/th&gt;
            &lt;th&gt;4&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;th scope="row"&gt;Comment&lt;/th&gt;
            &lt;td&gt;OBJ&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;STOP&lt;/td&gt;
            &lt;td&gt;IMG&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;th scope="row"&gt;\( R \)&lt;/th&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;\( \infty \)&lt;/td&gt;
            &lt;td&gt;-9.750&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;th scope="row"&gt;\( t \)&lt;/th&gt;
            &lt;td&gt;29.4702&lt;/td&gt;
            &lt;td&gt;2&lt;/td&gt;
            &lt;td&gt;15.97699&lt;/td&gt;
            &lt;td&gt;17.323380&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;th scope="row"&gt;\( n \)&lt;/th&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;1.610248&lt;/td&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;th scope="row"&gt;\( C \)&lt;/th&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;0&lt;/td&gt;
            &lt;td&gt;-0.10256&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
         &lt;/tr&gt; 
        &lt;tr&gt;
            &lt;th scope="row"&gt;\( -\Phi \)&lt;/th&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;0&lt;/td&gt;
            &lt;td&gt;-0.06259&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;th scope="row"&gt;\( t/n \)&lt;/th&gt;
            &lt;td&gt;29.4702&lt;/td&gt;
            &lt;td&gt;1.24204&lt;/td&gt;
            &lt;td&gt;15.97699&lt;/td&gt;
            &lt;td&gt;17.323380&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;th scope="row"&gt;\( y \)&lt;/th&gt;
            &lt;td&gt;0&lt;/td&gt;
            &lt;td&gt;29.4702&lt;/td&gt;
            &lt;td&gt;30.712240&lt;/td&gt;
            &lt;td&gt;15.97699&lt;/td&gt;
            &lt;td&gt;0&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;th scope="row"&gt;\( nu \)&lt;/th&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;-0.922279&lt;/td&gt;
            &lt;td&gt;-0.922279&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;th scope="row"&gt;\( \bar{y} \)&lt;/th&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;1&lt;/td&gt;
            &lt;td&gt;0&lt;/td&gt;
            &lt;td&gt;-1.084270&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;th scope="row"&gt;\( n \bar{u} \)&lt;/th&gt;
            &lt;td&gt;0&lt;/td&gt;
            &lt;td&gt;0&lt;/td&gt;
            &lt;td&gt;-0.06259&lt;/td&gt;
            &lt;td&gt;-0.06259&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This system is shown below with lens semi-diameters of 5 mm. Note that the stop is at the paraxial focus of the lens. The rays in the sketch cross the axis before the stop because of spherical aberration.&lt;/p&gt;
&lt;p&gt;&lt;svg viewbox="0, 0, 1344, 150" width="120%" fill="none" stroke="black" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M 632.646354675293 142.5 L 632.646354675293 142.5 L 632.646354675293 142.5 L 632.646354675293 135.39473819732666 L 632.646354675293 128.2894731760025 L 632.646354675293 121.18420815467834 L 632.646354675293 114.078946352005 L 632.646354675293 106.97368454933167 L 632.646354675293 99.86841952800751 L 632.646354675293 92.76315450668335 L 632.646354675293 85.65789270401001 L 632.646354675293 78.55263090133667 L 632.646354675293 71.44736909866333 L 632.646354675293 64.34210085868835 L 632.646354675293 57.236839056015015 L 632.646354675293 50.131577253341675 L 632.646354675293 43.0263090133667 L 632.646354675293 35.92104721069336 L 632.646354675293 28.81578540802002 L 632.646354675293 21.71052360534668 L 632.646354675293 14.60526180267334 L 632.646354675293 7.5 L 632.646354675293 7.5 L 641.0208705067635 7.5 L 641.0208705067635 7.5 L 644.972696185112 14.60526180267334 L 648.3765449523926 21.71052360534668 L 651.27783036232 28.81578540802002 L 653.7113556861877 35.92104721069336 L 655.7038663029671 43.0263090133667 L 657.275763630867 50.131577253341675 L 658.4422525763512 57.236839056015015 L 659.2141510248184 64.34210085868835 L 659.5984016060829 71.44736909866333 L 659.5984016060829 78.55263090133667 L 659.2141510248184 85.65789270401001 L 658.4422541856766 92.76315450668335 L 657.275763630867 99.86841952800751 L 655.7038679122925 106.97368454933167 L 653.7113556861877 114.078946352005 L 651.2778335809708 121.18420815467834 L 648.3765481710434 128.2894731760025 L 644.972696185112 135.39473819732666 L 641.0208705067635 142.5 L 641.0208705067635 142.5 L 632.646354675293 142.5 Z" stroke="black" stroke-width="1" stroke-linejoin="bevel" fill="none"&gt;&lt;/path&gt;&lt;path d="M 632.646354675293 142.5 L 632.646354675293 142.5 L 632.646354675293 135.39473819732666 L 632.646354675293 128.2894731760025 L 632.646354675293 121.18420815467834 L 632.646354675293 114.078946352005 L 632.646354675293 106.97368454933167 L 632.646354675293 99.86841952800751 L 632.646354675293 92.76315450668335 L 632.646354675293 85.65789270401001 L 632.646354675293 78.55263090133667 L 632.646354675293 71.44736909866333 L 632.646354675293 64.34210085868835 L 632.646354675293 57.236839056015015 L 632.646354675293 50.131577253341675 L 632.646354675293 43.0263090133667 L 632.646354675293 35.92104721069336 L 632.646354675293 28.81578540802002 L 632.646354675293 21.71052360534668 L 632.646354675293 14.60526180267334 L 632.646354675293 7.5" stroke="black" stroke-width="1" stroke-linejoin="miter" fill="none"&gt;&lt;/path&gt;&lt;path d="M 875.3357162475586 142.5 L 875.3357162475586 142.5 L 875.3357162475586 81.75" stroke="black" stroke-width="1" stroke-linejoin="miter" fill="none"&gt;&lt;/path&gt;&lt;path d="M 875.3357162475586 68.25 L 875.3357162475586 68.25 L 875.3357162475586 7.5" stroke="black" stroke-width="1" stroke-linejoin="miter" fill="none"&gt;&lt;/path&gt;&lt;path d="M 641.0208705067635 142.5 L 641.0208705067635 142.5 L 644.972696185112 135.39473819732666 L 648.3765481710434 128.2894731760025 L 651.2778335809708 121.18420815467834 L 653.7113556861877 114.078946352005 L 655.7038679122925 106.97368454933167 L 657.275763630867 99.86841952800751 L 658.4422541856766 92.76315450668335 L 659.2141510248184 85.65789270401001 L 659.5984016060829 78.55263090133667 L 659.5984016060829 71.44736909866333 L 659.2141510248184 64.34210085868835 L 658.4422525763512 57.236839056015015 L 657.275763630867 50.131577253341675 L 655.7038663029671 43.0263090133667 L 653.7113556861877 35.92104721069336 L 651.27783036232 28.81578540802002 L 648.3765449523926 21.71052360534668 L 644.972696185112 14.60526180267334 L 641.0208705067635 7.5" stroke="black" stroke-width="1" stroke-linejoin="miter" fill="none"&gt;&lt;/path&gt;&lt;path d="M 1109.2013397216797 142.5 L 1109.2013397216797 142.5 L 1109.2013397216797 135.39473819732666 L 1109.2013397216797 128.2894731760025 L 1109.2013397216797 121.18420815467834 L 1109.2013397216797 114.078946352005 L 1109.2013397216797 106.97368454933167 L 1109.2013397216797 99.86841952800751 L 1109.2013397216797 92.76315450668335 L 1109.2013397216797 85.65789270401001 L 1109.2013397216797 78.55263090133667 L 1109.2013397216797 71.44736909866333 L 1109.2013397216797 64.34210085868835 L 1109.2013397216797 57.236839056015015 L 1109.2013397216797 50.131577253341675 L 1109.2013397216797 43.0263090133667 L 1109.2013397216797 35.92104721069336 L 1109.2013397216797 28.81578540802002 L 1109.2013397216797 21.71052360534668 L 1109.2013397216797 14.60526180267334 L 1109.2013397216797 7.5" stroke="#999999" stroke-width="1" stroke-linejoin="miter" fill="none"&gt;&lt;/path&gt;&lt;path d="M 234.7986602783203 142.5 L 234.7986602783203 142.5 L 234.7986602783203 135.39473819732666 L 234.7986602783203 128.2894731760025 L 234.7986602783203 121.18420815467834 L 234.7986602783203 114.078946352005 L 234.7986602783203 106.97368454933167 L 234.7986602783203 99.86841952800751 L 234.7986602783203 92.76315450668335 L 234.7986602783203 85.65789270401001 L 234.7986602783203 78.55263090133667 L 234.7986602783203 71.44736909866333 L 234.7986602783203 64.34210085868835 L 234.7986602783203 57.236839056015015 L 234.7986602783203 50.131577253341675 L 234.7986602783203 43.0263090133667 L 234.7986602783203 35.92104721069336 L 234.7986602783203 28.81578540802002 L 234.7986602783203 21.71052360534668 L 234.7986602783203 14.60526180267334 L 234.7986602783203 7.5" stroke="#999999" stroke-width="1" stroke-linejoin="miter" fill="none"&gt;&lt;/path&gt;&lt;path d="M 234.7986602783203 115.5 L 234.7986602783203 115.5 L 632.646354675293 115.5 L 653.2606882452965 115.5 L 875.3357162475586 69.18727111816406 L 1109.2013397216797 20.41567325592041" stroke="red" stroke-width="0.5" stroke-linejoin="miter" fill="none"&gt;&lt;/path&gt;&lt;path d="M 234.7986602783203 75 L 234.7986602783203 75 L 632.646354675293 75 L 659.646354675293 75 L 875.3357162475586 75 L 1109.2013397216797 75" stroke="red" stroke-width="0.5" stroke-linejoin="miter" fill="none"&gt;&lt;/path&gt;&lt;path d="M 234.7986602783203 34.5 L 234.7986602783203 34.5 L 632.646354675293 34.5 L 653.2606882452965 34.5 L 875.3357162475586 80.81272888183594 L 1109.2013397216797 129.5843267440796" stroke="red" stroke-width="0.5" stroke-linejoin="miter" fill="none"&gt;&lt;/path&gt;&lt;path d="M 234.7986602783203 2451228.234375 L 234.7986602783203 2451228.234375 L 632.646354675293 2451193.4296875" stroke="red" stroke-width="0.5" stroke-linejoin="miter" fill="none"&gt;&lt;/path&gt;&lt;path d="M 234.7986602783203 2451187.734375 L 234.7986602783203 2451187.734375 L 632.646354675293 2451152.9296875" stroke="red" stroke-width="0.5" stroke-linejoin="miter" fill="none"&gt;&lt;/path&gt;&lt;path d="M 234.7986602783203 2451147.234375 L 234.7986602783203 2451147.234375 L 632.646354675293 2451112.4296875" stroke="red" stroke-width="0.5" stroke-linejoin="miter" fill="none"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/p&gt;
&lt;h2&gt;Remarks&lt;/h2&gt;
&lt;h3&gt;Marginal ray trace&lt;/h3&gt;
&lt;p&gt;At first the marginal ray trace was a bit confusing because the entrance pupil is at infinity. How can the marginal ray, which intersects the pupil at its edge, be traced when the pupil is at infinity? Then I remembered that I don't aim for the edge of the pupil when tracing the marginal ray. Instead, I launch a ray from the axis in the object plane at a random angle taking the surface with the smallest ray height as the aperture stop. (I chose a paraxial angle of 1 in the table above. Technically, this is called a pseudo-marginal ray. The real marginal ray is calculated from it by rescaling the surface intersection heights by the aperture stop semi-diameter.) Once you have the marginal ray in image space, just find its intersection with the axis to determine the image location.&lt;/p&gt;
&lt;h3&gt;Telecentric lens design&lt;/h3&gt;
&lt;p&gt;So how would an object-space telecentric design be implemented in software? First, I'd set an option that would force the chief ray angle to 0 in the object space. Then, I'd simply place a solve on the aperture stop that puts it at the location where the chief ray intersects the axis.&lt;/p&gt;</description><category>ray tracing</category><category>telecentricity</category><guid>https://kylemdouglass.com/posts/a-simple-object-space-telecentric-system/</guid><pubDate>Mon, 11 Mar 2024 07:59:17 GMT</pubDate></item><item><title>Fusion 360 Core Concepts</title><link>https://kylemdouglass.com/posts/fusion-360-core-concepts/</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;p&gt;I decided recently to learn Fusion 360 to help with some custom optomechanical designs that I need in the lab. The following are my notes about its core concepts.&lt;/p&gt;
&lt;h2&gt;Assemblies&lt;/h2&gt;
&lt;p&gt;An assembly is a group of parts in one design file.&lt;/p&gt;
&lt;p&gt;In CAD, there are two ways to create assemblies:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Bottom-up&lt;/strong&gt;&lt;ol&gt;
&lt;li&gt;Create parts&lt;/li&gt;
&lt;li&gt;Add parts to the assembly&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Top-down&lt;/strong&gt; (used by Fusion 360)&lt;ol&gt;
&lt;li&gt;Start with an assembly&lt;/li&gt;
&lt;li&gt;Add parts to it&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Bodies vs. components&lt;/h2&gt;
&lt;h3&gt;Bodies&lt;/h3&gt;
&lt;p&gt;A body is a 3D shape used to add or remove components.&lt;/p&gt;
&lt;p&gt;There are two core types:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Solid bodies&lt;/li&gt;
&lt;li&gt;Surface bodies (denoted by a yellow face)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Other types include T-Splines (created in the Form environment) used to create freeform shapes, and mesh bodies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bodies must be of the same type to interact with one another.&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;Components&lt;/h3&gt;
&lt;p&gt;A component is a part or "container" used within an assembly.&lt;/p&gt;
&lt;p&gt;Components can contain&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bodies&lt;/li&gt;
&lt;li&gt;construction planes&lt;/li&gt;
&lt;li&gt;sketches&lt;/li&gt;
&lt;li&gt;canvases&lt;/li&gt;
&lt;li&gt;origin planes&lt;/li&gt;
&lt;li&gt;other components (a.k.a. &lt;strong&gt;subassemblies&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Joints&lt;/h2&gt;
&lt;p&gt;Joints are how components are forced to stay together.&lt;/p&gt;
&lt;h2&gt;Guidelines&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Always start an assembly with a new component&lt;/li&gt;
&lt;li&gt;Always rename components and bodies right after creation&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=TzG2deElWqI&amp;amp;t=0s"&gt;Bodies vs Components&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description><category>cad</category><guid>https://kylemdouglass.com/posts/fusion-360-core-concepts/</guid><pubDate>Fri, 08 Mar 2024 14:16:22 GMT</pubDate></item></channel></rss>